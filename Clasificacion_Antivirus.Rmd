---
title: "Proyecto Virus Total"
author: "Francisco Jose Garcia Barbero"
date: '2022-05-19'
output: html_document
---
 
# Proyecto de análisis de datos sobre los JSON de virus total.

## Cargamos las librerias que vamos a usar durante el proyecto:
```{r include=FALSE}
library(jsonlite)
library(curl)
library(tidyjson)
library(dplyr)
library(purrr)
library(tidyverse)
library(jsonlite)
library(rjson)
library(fcaR)
library(parallel)
library(rlist)
library(kableExtra)
library(factoextra)
library(fpc)
library(hasseDiagram)
library(plotly)
library(dash)
library(dashCoreComponents)
library(dashHtmlComponents)
library(ggfortify)
library(ggdendro)
library(heatmaply)

```

## Ruta de trabajo

```{r}
path <- "~/clase/proyecto r/ProyectoVirusTotal/Android"
```

## Operación de carga de datos
Guardamos todos los JSON en un array de characters, y los cargamos mediante un cluster donde vamos a paralelizar la lectura de los JSON, puesto que de esta es la forma más eficiente, pruebas de rendimiento en el anexo. Usaremos simplifyVector con el read_json ya que nos generará un archivo de menor tamaño y por tanto usaremos menos memoria y el spread_all consumirá menos tiempo para crear el dataset que a su vez también ocupará menos.

```{r}
files <- dir(path, pattern = "*.json")
cl <- makeCluster(detectCores() -1 )
json_files<-list.files(path =path,pattern="*.json",full.names = TRUE)

json_list<-parLapply(cl,json_files,function(x) jsonlite::read_json(path = x , simplifyVector = TRUE))
stopCluster(cl)
```

##  Transformación a dataset para primera exploración
Una vez cargados todos los json en una lista, los vamos a transformar en una tabla con la que podremos manejarla para crear los datasets, y posteriormente filtramos todas las columnas que sean NA, una vez hecho esto decidimos que la primero que queremos hacer es un clasificador de antivirus, mediante cluster con kmeans, dendograma y fcaR.
```{r eval=FALSE, echo=TRUE}
json_tabla <- json_list %>%
  spread_all()
json_tabla_no_na <- json_tabla %>% select_if(~!all(is.na(.)))
```

## Filtrado de columnas previo

Dado que ya hemos cargado los datos y sabemos con que columnas queremos trabajar, podemos filtrarlas desde la lista de todos los json en vez de crear el dataset y luego filtrarlas, esto nos permite crear un nuevo listado que ocupará la mitad de almacenamiento y es apróximadamente un 30% más rápido en ejecutarse incluso con esta muestra reducida de 183 objectos, haciéndolo mucho más eficiente que la opción de crear un dataset y realizarle un select para hacer la selección. 

``` {r}

json_list_filtrados <- lapply(json_list, `[`, c('sha256',"total", "positives",'scans'))

json_tabla_filtrado <- json_list_filtrados %>%
  spread_all()

```


## Selección de columnas
Vamos a usar sha256 como el identificador de cada posible archivo y extraeremos también el número de positivos y lo que ha detectado cada antivirus el problema con ese resultado es que no podemos asegurar que no tenga NA, así que hay que filtrarlo posteriormente.

```{r}
sha_datos_scans.detected <- as.data.frame(json_tabla_filtrado) %>% select( sha256, total, positives , matches("scans.*.detected"))
## Los datos numéricos únicamente para evitar dolores de cabeza.
datos_scans.detected <- as.data.frame(json_tabla_filtrado) %>% select(  matches("scans.*.detected") )
## Nos sirve para pasar los true y false a 1 o 0.
datos_procesados <- data.frame(datos_scans.detected*1)

``` 

## Filtrado de datos
Se crea un tabla para poder contar el número de NA que tenemos en la detección de los antivirus, posteriormente los ordenamos de mayor a menor y extraemos el nombre de las filas extrayendo la parte .NA del archivo, lo que nos servirá para ir filtrando en el siguiente bucle.

```{r}
tabla_total <- sapply(datos_procesados, table, useNA="always" )
tabla_df_total <- data.frame(t(unlist(tabla_total)))
tabla_NAs <- as.data.frame(t(select(tabla_df_total , matches( "*.NA$"))))
tabla_NAs <- arrange(tabla_NAs, desc(V1) )
nombres_eliminar<- gsub( ".{3}$", "", row.names(tabla_NAs))
```

Cargamos la tabla con los sha y los antivirus y le realizamos un reemplazo de los - por . para que estén en el mismo formato que nombres_eliminar, y posteriormente creamos un bucle que nos servirá para ir eliminando filas y columnas que tengan resultados NA hasta quedarnos con mínimo un 90% de filas respecto de la muestra inicial, finalmente eliminamos las filas con NA de nuestro dataframe, donde sacaremos nuestra nueva tabla con los resultados de los antivirus esta vez sin ningún NA, y nos guardamos un dataframe con la cantidad de resultados positivos de cada antivirus para posterior comprobaciones con los modelos que obtendremos.

```{r, warning=FALSE, message=FALSE}
json_df_filtrados<-sha_datos_scans.detected
colnames(json_df_filtrados)<-gsub("-" , ".", colnames(json_df_filtrados))
json_df_filtrados<-as.data.frame(json_df_filtrados)
i<-1
total_filas<-0
total<-nrow(sha_datos_scans.detected)
while (total_filas < total*0.9) {
  mayor<- nombres_eliminar[i]
  json_df_filtrados <- select(json_df_filtrados, -mayor)
  total_filas <- nrow (na.omit(json_df_filtrados))
  i<-i+1
}

json_df_filtrados<- na.omit(json_df_filtrados)
colnames(json_df_filtrados) <- gsub("scans.","",colnames(json_df_filtrados))
colnames(json_df_filtrados) <- gsub(".detected","",colnames(json_df_filtrados))
datos_df_filtrados <- as.data.frame(select(json_df_filtrados, -c("sha256","total","positives")))
tabla <- sapply(datos_df_filtrados , table)
tabla_df <- data.frame(t(unlist(tabla)))
tabla_unos <- as.data.frame(t(select(tabla_df , matches( "*.TRUE$"))))
```

## Kmeans
Haciendo el nbclust nos sale que el valor óptimo de clúster es 2, sin embargo he optado por hacer 5 clústers ya que cuando hacía la visualización quedan mejor agrupados los valores. El resultado se visualiza mediante un gráfico interactivo donde puedes ver el valor de cada nodo con el antivirus al que corresponde.

```{r echo=TRUE}
fviz_nbclust(t(json_df_filtrados[,4:45]), kmeans, nstart= 10) 
test_kmeans <- kmeans(t(json_df_filtrados[,4:45]), centers = 5, nstar=100)
grafico_kmeans<- fviz_cluster(test_kmeans, data = t(json_df_filtrados[,4:45]) , geom=c("point", "text"))+ geom_point(aes(color=cluster, text = name))
grafico_kmeans$layers[[4]] <- NULL
grafico_kmeans$layers[[3]] <- NULL
grafico_kmeans$layers[[1]] <- NULL
ggplotly(grafico_kmeans)

```

## Dendograma
Ahora probamos a realizarle un análisis usando un dendograma y luego lo agruparemos en 5 clústers para comprobar si se corresponden con el resultado de kmeans.

```{r}
distancias <- dist(t(datos_df_filtrados))
distancias %>% fviz_dist()
clusters <- distancias %>% hclust()
plot(clusters, main="Detectado Antivirus" )
rect.hclust(clusters, k=5 )
dendograma <- ggdendrogram(clusters, rotate = FALSE)

```

Y ahora mostramos el dendograma en versión interactiva.
```{r}
ggplotly(dendograma)
```

## Funciones para visualización de fcaR
La función plot_interactivo nos devolverá un objeto plot_ly donde estará nuestra representación gráfica del fcaR.
En la función plot_dendograma, dibujará el mapa de calor donde las columnas y las filas estarán ordenadas en función del resultado del dendograma, se le puede pasa opciones de la función heatmap.

```{r}
plot_interactivo <- function(fca){
  matriz_descompuesta <- as.matrix(t(fca[["I"]]))
  plot_interactivo <- plot_ly(z=matriz_descompuesta, data=as.data.frame(matriz_descompuesta), type = "heatmap", colors = "Greys", x=colnames(matriz_descompuesta), y=rownames(matriz_descompuesta))%>% layout(xaxis = list(autotypenumbers ='strict', type='category'), yaxis = list(autotypenumbers ='strict', dtick=1 ))
  return(plot_interactivo)
}
plot_dendograma <- function(fca){
  matriz_descompuesta <- as.matrix(t(fca[["I"]]))
  heatmap(matriz_descompuesta, col=c("White","Black"))
}
plot_dendograma_interactico <- function(fca){
  matriz_descompuesta <- as.matrix(t(fca[["I"]]))
  heatmaply(matriz_descompuesta, col=c("White","Black"))
}
```

## Formal Concepts Analysis
A continuación voy a aplicar FCA y sacaré la representación del plot de fca en un mapa de calor, usando las funciones de plot_interactivo, plot_dendograma y plot_dendograma_interactivo. Obtenemos un total de 24 conceptos irreducibles que serían los grupos de antivirus que hay y 75 implicaciones irreducibles que se corresponderían a los grupos de archivos con resultados distintos.

```{r}
datos_df_filtrados <- datos_df_filtrados*1
atributes <- colnames(datos_df_filtrados)
json_df_filtrados<- cbind(json_df_filtrados[,1:3], datos_df_filtrados)

fc_detected <- FormalContext$new(datos_df_filtrados)
fc_detected$clarify()
fc_detected$reduce()
fc_detected$plot()
fc_detected$find_concepts()
fc_detected$find_implications()
fc_detected$standardize()

fc_detected$implications
mapa_calor <- plot_interactivo(fc_detected)
mapa_calor

plot_dendograma(fc_detected )

```

En el siguiente cuaderno realizaremos la predicción de los posibles positivos que darían en función de los permisos que teng el archivo.

# Bibliografía de este cuaderno
 https://www.r-bloggers.com/2020/03/what-is-a-dgcmatrix-object-made-of-sparse-matrix-format-in-r/
 https://cran.r-project.org/web/packages/heatmaply/vignettes/heatmaply.html
 https://plotly.com/r/axes/
 https://statisticsglobe.com/heatmap-in-r
 https://www.displayr.com/what-is-dendrogram/
 https://github.com/colearendt/tidyjson
 https://cran.microsoft.com/snapshot/2017-08-01/web/packages/tidyjson/vignettes/introduction-to-tidyjson.html
 https://rdrr.io/cran/tidyjson/f/vignettes/introduction-to-tidyjson.Rmd
 https://hendrikvanb.gitlab.io/2018/07/nested_data-json_to_tibble/
 https://stackoverflow.com/questions/35421870/reading-multiple-json-files-in-a-directory-into-one-data-frame Pero hemos usado read_json para usar el spread_all
 http://gradientdescending.com/simple-parallel-processing-in-r/
 https://cran.r-project.org/web/packages/jsonlite/jsonlite.pdf
 https://blog.dominodatalab.com/multicore-data-science-r-python
 https://stackoverflow.com/questions/23758858/how-can-i-extract-elements-from-lists-of-lists-in-r
 https://stats.stackexchange.com/questions/31083/how-to-produce-a-pretty-plot-of-the-results-of-k-means-cluster-analysis
 https://uc-r.github.io/kmeans_clustering
 https://www.rstudio.com/resources/cheatsheets/
 https://rubenfcasal.github.io/aprendizaje_estadistico/cart-con-el-paquete-rpart.html
 https://plotly.com/ggplot2/dendrogram/
 https://github.com/neuroimaginador/fcaR/blob/master/R/formal_context.R